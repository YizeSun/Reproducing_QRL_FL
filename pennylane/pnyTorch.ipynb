{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, assemble, Aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('qiskit.aer', wires = 4)\n",
    "\n",
    "def layer(weights):\n",
    "    # Entanglement block\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.CNOT(wires=[2,3])\n",
    "    # u3 gate\n",
    "    qml.Rot(weights[0, 0], weights[0, 1], weights[0, 2], wires=0)\n",
    "    qml.Rot(weights[1, 0], weights[1, 1], weights[1, 2], wires=1)\n",
    "    qml.Rot(weights[2, 0], weights[2, 1], weights[2, 2], wires=2)\n",
    "    qml.Rot(weights[3, 0], weights[3, 1], weights[3, 2], wires=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(encodings):\n",
    "        return [i for i, b in enumerate(encodings) if b == '1']\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def qc(weights, encoding = None):\n",
    "    # encoding\n",
    "    if encoding:\n",
    "        encoder = encoder(encoding)\n",
    "        qml.RX(np.pi, wires=encoder)\n",
    "        qml.RZ(np.pi, wires=encoder)\n",
    "    #layerwise\n",
    "    for w in weights:\n",
    "        layer(w)\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(4)]\n",
    "    \n",
    "def variational_qc(weights, bias, encoding = None):\n",
    "    return qc(weights, encoding = encoding) + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(targs, preds):\n",
    "    return sum([(tar - pred)**2 for tar, pred in zip(targs, preds)])/len(targs)\n",
    "\n",
    "def cost(weights, bias, batch_features, v_targets):\n",
    "    v_preds = [variational_qc(weights, bias, encoding=b['state'])[b['action']] for b in batch_features]\n",
    "    return mse(v_targets, v_preds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
